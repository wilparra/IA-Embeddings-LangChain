{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fbc1c1-5c8a-47d4-857d-5efcea307735",
   "metadata": {},
   "source": [
    "# Preparar entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0367090-5ada-4970-8122-d361c9ae0e72",
   "metadata": {},
   "source": [
    "## Instalar Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e1f7b-cf84-4955-9f96-ec63918f7cd7",
   "metadata": {},
   "source": [
    "### Instalar librerias para sugerencias de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680430b-1d88-4438-9934-54c0f71c2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_contrib_nbextensions\n",
    "!pip install jupyter_nbextensions_configurator\n",
    "!jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8026c-7104-4c32-88f8-32db905504b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79601c4-cd0f-4937-9ca8-52b2bf85c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ae1da-ae1a-4b57-8115-16e4388a3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bd4b9-aca4-4bd0-a8f7-cbcfe48019e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b294b08-78bd-45bc-93de-aa13939200a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ea909-662d-4feb-9cac-6ff26f95f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a4634e-29d1-483d-a0e1-ae4bdaff4416",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762377c-afce-4669-96e1-baaa529d081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6d868-6b9d-4a56-b05c-c94cef745252",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Describe un objeto que te resulte {adjetivo} y por qué tiene ese efecto en tí\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c25acc-b8bf-4dc1-bb71-66f6f9c3b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.format(adjetivo=\"fascinante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6415a-36b4-4514-9ca9-b047258c91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.format(adjetivo=\"feo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb07dc-fb32-4ab5-ac44-f681437337cc",
   "metadata": {},
   "source": [
    "## Cadenas con propmt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f7e5a-59d7-4ce2-880d-9e642b61477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Eres un asistente util que traduce del {idioma_entrada} al {idioma_salida} el texto {texto}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba9daa-afda-41b4-a900-3e7926a8acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee5c46-7fe3-4b19-9414-5e1b8c599a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"Me encanta programar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e5710-5e6a-49ab-b568-fcc2d07fedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"idioma_entrada\",\"idioma_salida\",\"texto\"],template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4fa94-9bc8-43d3-b63e-2f0d33a15696",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d77f6c-1282-45b7-b46f-32ceef8f7083",
   "metadata": {},
   "source": [
    "### Llamando al LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecda2b-c33d-4470-93e2-59ce75599963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89809c2c-3ba7-4bb6-a219-66c8915b9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature = 1,\n",
    "    model_name = \"gpt-4.1-2025-04-14\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1390c-bcc8-4b42-a710-a7229a605827",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debido a que no hay creditos disponibles de OPENIA, se usara un modelo de GeminAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73674816-22ab-441b-b909-902b59f25a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53106ae6-9270-4d42-b9ec-99441d2b99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab989f2-3ccc-4c3f-987d-9d793d2a2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e10e33-9f63-41dc-acf5-c8fda74c986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = chain.invoke(input={\"idioma_entrada\":\"español\",\"idioma_salida\":\"francés\",\"texto\":texto})\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b88de-9ec0-4ba1-a610-5e649dd55497",
   "metadata": {},
   "source": [
    "### Obtener informacion de peliculas (Sin langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b291c-ed16-4d72-8efe-c7d1a05df40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bf4f7-4511-43ac-b5e5-3352696cb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b84fc-8433-4dee-8ae4-3e9492651180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "pelicula = \"titanic\"\n",
    "#url = \"https://api.themoviedb.org/3/authentication\"\n",
    "url = f\"https://api.themoviedb.org/3/search/movie?query={pelicula}&include_adult=false&language=en-US&page=1\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer *******\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "respuesta = response.json()\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9647c4-0922-400f-a302-15021b46b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen = respuesta[\"results\"][0][\"overview\"]\n",
    "print(resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee937964-6f9d-4c9f-aa4b-b4a62d15b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo = respuesta[\"results\"][0][\"original_title\"]\n",
    "print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa385cc-e71a-4d42-82e9-9520ecc1781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = respuesta[\"results\"][0][\"release_date\"]\n",
    "print(fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339d577-502c-41b0-826e-e4197b472c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(respuesta[\"results\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a1f3d-442e-417e-8c05-6cdc656d3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(len(respuesta[\"results\"]),3)):\n",
    "    titulo = respuesta[\"results\"][i][\"original_title\"]\n",
    "    resumen = respuesta[\"results\"][i][\"overview\"]\n",
    "    fecha = respuesta[\"results\"][i][\"release_date\"]\n",
    "    print(f\"\"\" Titulo: {titulo}\n",
    "    Fecha de entreno: {fecha}\n",
    "    Resumen: {resumen}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd125940-409a-4289-b26f-af9203ffe2bc",
   "metadata": {},
   "source": [
    "### Obtener información de peliculas con langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db405e3-0fd3-4068-9ba2-c5f4fb248837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envolver la conexion al servicio en un metodo de python\n",
    "import requests\n",
    "def peliculas(pelicula):\n",
    "    url = f\"https://api.themoviedb.org/3/search/movie?query={pelicula}&include_adult=false&language=en-US&page=1\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer ******\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362eeb6b-7d87-49c3-8d26-6091757d5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Te voy a dar informacion sobre algunas peliculas, me tienes que dar la informacion (en español) \n",
    "del titulo, fecha de estreno y resumen de las primeras 3 que aparezcan de forma estructurada (si aparecen menos, me das las que aparezcan).\n",
    "{respuesta}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ba9d4-c5d8-4b0e-8d86-b64479db916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"respuesta\"], template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f66c36-b4fa-4308-8ec1-c14b93ff8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora llamamos al modelo de IA. Usamos GeminIA porque OpenIA es de paga\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ca589-bc3d-4995-b74b-3501751534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48612591-2876-446f-a3da-0e5bdc4c8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta=peliculas(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b91287-0b3d-418c-b539-6911f718430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(respuesta=respuesta.text))\n",
    "#print(chain.invoke({\"respuesta\": respuesta.text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145c21d-b2e5-4bc1-80d9-2488f5e2c548",
   "metadata": {},
   "source": [
    "# Cadenas Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186e97a-f7cf-41d8-99cd-0a4b52ab602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d5dea-25a6-446b-8c18-a6d44d9d8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf31000-7c27-425a-9e29-a91d03ba0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Eres un detective experimentado. Describe las pistas clave que condujeron a resolver el caso de \n",
    "{caso} en {ciudad}. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8df019-37bd-4bbe-afb0-d40a8ebcac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fb1b3-15a9-401e-98aa-e66308e00915",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_template,\n",
    "    verbose = True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ed681-7645-4b12-bc2d-3520c069bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({'caso':'Desaparicion de la madrastra','ciudad':'Londres'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c3b84-2eb8-4e51-a2b8-32d3cdc9eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b892fe8-d1c2-450e-bf41-88ede6e1c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cb746-7d47-4e70-b49d-32d75344d37e",
   "metadata": {},
   "source": [
    "## Cadenas secuenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54ac56-bff9-43c7-ba13-c6e683c397f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812bb80-5f5d-4794-893e-fa8691485be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm1 = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850f879-f2d5-42f9-80dc-2b7dc40b4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"Eres un científico experimentado y programador en Python. \n",
    "Escriba una funcion que implemente el concepto de {concepto}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf24d47-a8f3-4277-944b-14d7020f2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template=\"Eres un científico experimentado y programador en Python. Escriba una funcion que implemente el concepto de {concepto}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af79fe-94a8-4e53-b678-906ee81c394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = LLMChain(\n",
    "    llm = llm1,\n",
    "    prompt = prompt_template1,\n",
    "    verbose = True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e698c-4041-4a1c-b586-5b0dc714a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora creamos un modelo 2\n",
    "llm2 = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=1.2,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3d51e-870c-41cb-a8d4-fd2dafc1e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template=\"Dada la funcion Python {funcion}. Descríbela lo más detalladamente posible.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795a64f-471a-4ca9-b3a9-a10c0d390acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain2 = LLMChain(\n",
    "    llm = llm2,\n",
    "    prompt = prompt_template2,\n",
    "    verbose = True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4e1a8-4ae9-4fd7-b774-a45a1935d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear una cadena secuencial\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1,chain2], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e6f0b-0ea8-45c5-b3d0-63b7df0dc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora le parametrizamos el concepto 'obtener los primeros \"n\" números primos'\n",
    "output = overall_chain.invoke('obtener los primeros \"n\" números primos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e4e6c-71be-4849-96c0-3e20f54615ea",
   "metadata": {},
   "source": [
    "## ReAct Agent (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e14c24-1f04-41cf-91bb-73a6d5d9af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7975d75-7c01-4f4a-bf7d-359ef4f8beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156231d5-910c-4619-8bd5-92d311edb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke('explica el procesamiento de lenguaje natural en una oración')\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f39fd0-d130-4f25-8977-ed629a0e03d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de2ffe-c0e7-4933-a19e-637fada1f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='Eres un chef y respondes solo con conceptos culinarios'),\n",
    "    HumanMessage(content='explica procesamiento del lenguaje natural en una oración')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ab739-2bab-4d63-865a-4ae3e809978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le entregamos los messages y ejecutamos\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a40e0-abd8-4126-aa44-4e5662c7a4a5",
   "metadata": {},
   "source": [
    "## Agentes en acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c94e3c-ed54-490e-ba44-43692d227b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_experimental -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f2dae-1644-4373-8230-0733796e6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(0,100) if n%13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108ab42-1536-4e78-bdc7-8a2172c2dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c020233-cd98-46ec-a4ca-8668f9154d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entre mas cerca a cero esté la temperatura del modelo, más determinístico; y entre más cerca a dos, el modelo es mas creativo\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bd765-1574-471a-bd20-5f8abbac3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbcba1f-9c4b-4a76-8d47-d4eef71eef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Encuentra el promedio de los cubos de los numeros del 1 al 10 y fuerza a que se vean 3 decimales'\n",
    "respuesta = agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd6a3f-2949-4c1d-8d0c-3a6c6c12ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuesta['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7537f-1c49-4d64-affb-09592364d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuesta['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc2b34-4fa0-43da-b09c-ce7188e7ba0e",
   "metadata": {},
   "source": [
    "## LangChain Tools: DuckDuckGo and Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bc878-5906-4f7b-b679-d4daa75d8d97",
   "metadata": {},
   "source": [
    "### DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adc0de-8db3-4449-8611-1276046d6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2e945-da36-46ee-a7a9-1fc02c6cdc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd4953-0f67-4375-a577-2c9c319e2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b602a-603f-458f-87d6-c9d9303a3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = search.invoke('¿Cuál es el principal ingrediente de la pizza Margarita?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34cd63-975d-48fb-8924-b1d5bb14f8e1",
   "metadata": {},
   "source": [
    "### Otra forma de usar esta libreria (con método run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63cead3-4225-4ca9-b359-5ecf03de1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run('¿Cuál es el principal ingrediente de la pizza Margarita?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37882608-d29c-4ef3-897b-7f36b0cb70b9",
   "metadata": {},
   "source": [
    "### Ahora con un Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f927c89-0f6f-4742-9ac7-f50f028e8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01112b4c-eee2-4e9a-b732-74518ce2c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = DuckDuckGoSearchAPIWrapper(region='co-es', max_results=3, safesearch='moderate')\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source='news')\n",
    "output = search.run('nvidia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becb754-89ad-4591-85c5-a1f6c641050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7111a36c-bbe8-43e4-8c46-28983616d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = search.run('William Enrique Parra Alba')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d8f5b-f344-4060-92ef-36f8278f245e",
   "metadata": {},
   "source": [
    "#### Se puede dar un poco mas de formato a la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac2cf5-2426-40bb-b9cf-f596ed878303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'snippet: (.*?), title: (.*?), link: (.*?)\\],'\n",
    "matches = re.findall(pattern, output, re.DOTALL)\n",
    "#print(matches)\n",
    "for snippet, title, link in matches:\n",
    "    print(f'Snippet: {snippet}\\nTitle: {title}\\bnLink: {link}\\n')\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81d6f7-7dd2-4076-8472-1eafa1b68a97",
   "metadata": {},
   "source": [
    "## Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5ee4d-441d-43cc-b61c-34b5a27f0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c92799-d0ae-441e-a139-f3bcde71fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88adca7-2f08-49e3-a42d-09b9853413d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(lang='es', top_k_results=1, doc_content_chars_max=10000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "# Que busque sora de OpenAI\n",
    "wiki.invoke({'query':'sora de openai'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03bfb-3451-4194-8322-48d1ec8d543d",
   "metadata": {},
   "source": [
    "## Crear ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9d54b-5ce3-4c54-add1-e0915a23da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b3578-ea98-40df-a2ac-239dcf2735d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent, create_react_agent\n",
    "from langchain.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9d6fb-7da5-471c-97f2-b55b569f9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6251fd7-87a5-4c5b-90a6-96f2cc398b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Responde las siguientes preguntas en Italiano lo mejor que puedas.\n",
    "Preguntas: {q}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf93bd1-abb3-4f9f-8795-a43b2b1d26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0bf65-5394-4f86-b9fa-7bcafc81f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull('hwchase17/react')\n",
    "\"\"\"\n",
    "Este metodo te permite extraer y utilizar objetos, como agentes, configuraciones o plantillas,\n",
    "    que han sido compartidos en LangChain Hub por otros usuarios o creadores o default de langchain. En este caso particular\n",
    "    'hwchase17/react' hace referencia a una configuración o componente específico, que está relacionado con la funcionalidad.\n",
    "\n",
    "    Esta funcionalidad es particularmente útil cuando deseas implementar lógicas complejas o específicas sin\n",
    "    tener que desarrollar todo desde cero. Al aprovechar los componentes compartidos en LangChain Hub, puedes\n",
    "    enriquecer tus aplicaciones con funcionalidades avanzadas, facilitando el desarrollo de soluciones basadas\n",
    "    en modelos de lenguaje grande (LLM) y otras herramientas de procesamiento de lenguaje natural (NLP).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3fee7-aa40-4fc2-b692-a07faf8f0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Python REPL Tool\n",
    "python_repl = PythonREPLTool()\n",
    "python_repl_tool = Tool(\n",
    "    name = 'Python REPL',\n",
    "    func=python_repl.run,\n",
    "    description='Útil cuando necesitas usar Python para responder una pregunta. Debes ingresar código Python.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a16d177-eb77-4bdf-beaa-c46382c7b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Wikipedia tool\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wikipedia_tool = Tool(\n",
    "    name='Wikipedia',\n",
    "    func=wikipedia.run,\n",
    "    description='Útil cuando necesitas buscar un tema, país o persona en Wikipedia.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d763370-bd0a-40dd-bc45-799f8ea28ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DuckDuckGo Search Tool\n",
    "search = DuckDuckGoSearchRun()\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func=search.run,\n",
    "    description='Útil cuando necesitas realizar una búsqueda en internet para encontrar información que otra herramienta no puede proporcionar.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641f313-85b0-4856-87e9-6c2b29f72ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera una lista con las herramientas\n",
    "tools = [python_repl_tool, wikipedia_tool, duckduckgo_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8c81b-5f92-4209-9b0b-c46b6af22549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el agente\n",
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb445d2-305b-4a34-8d84-8b83a7c7672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ejecuta el agente\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817495c4-f247-4636-ac51-c29f4b293c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la consulta al agente\n",
    "question = 'Cuéntame sobre la vida temprana de Simón Bolívar'\n",
    "output = agent_executor.invoke({\n",
    "    'input':prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccd41a-4ee7-47ce-b06b-0d2a41f7b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pinta la respuesta en italiano\n",
    "output['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c0568-7b3e-4568-ae2c-a42224215304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora otra pregunta:\n",
    "question = '¿Qué país ganó la última copa del mundo de fútbol?'\n",
    "output = agent_executor.invoke({\n",
    "    'input':prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aec4b-022a-458f-a8ee-5d3779aec920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pinta la respuesta en italiano\n",
    "output['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ea990-1862-49f7-b5e3-0f4de5d036ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora esta otra pregunta:\n",
    "question = 'Determina los primeros 100 números primos'\n",
    "output = agent_executor.invoke({\n",
    "    'input':prompt_template.format(q=question)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41462f-ead7-43e4-8ee2-a036ac3e2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime la respuesta\n",
    "output['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d682e-3b73-449c-8732-54352c2f3508",
   "metadata": {},
   "source": [
    "## LangChain y Vector Stores (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bef9f-4787-4fcc-beac-01101bba9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos con base en vectores. Permite transformar datos de entrada en vectores y guardarlos para posteriores búsquedas por similitud.\n",
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd3707-d4bd-492e-bc46-3f4d39c6f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3041bb-b5e8-43ef-865e-2f6b16fe6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d543a1c-b88e-445f-826e-d5a39e04fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea5b1c-12c4-435b-823c-a9d675d6afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fc182-0496-4d24-a6e8-fc35e1ce7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ[\"PINECONE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465dbf3-7737-4ce2-8a16-e66487b06dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2846f-0bd6-46e7-bbdd-9e96a1b7ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820fef3-a8ea-447e-a668-aad80ba863ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022ef5e-897f-42c2-8467-84372ff61ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dead6d5-c77b-4cb5-b320-d523dd141f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03c2c6-bb2e-48f0-8b1e-b2316a5cee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba22fa7-f082-4354-87f2-56dca1d4c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'langchain'\n",
    "pc.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674f811-924a-4f85-9908-df77bbd06563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de todos los indices\n",
    "pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a36c2b-e602-4e14-8ba9-d58438974193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos borra el indice de Pinecone\n",
    "# pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f158dc-4a7e-4b9a-b94c-c5ef93b0fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dcf84-142c-4267-9428-d93a9adc0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un indice desde el código\n",
    "#from pinecone import PodSpec\n",
    "#index_name = 'langchain2'\n",
    "#pc.create_index(\n",
    "#    name=index_name,\n",
    "#    dimension=3072,\n",
    "#    metric='cosine',\n",
    "#    spec=PodSpec(\n",
    "#        environment='gcp-starter'\n",
    "#    )\n",
    "#)\n",
    "print(\"echo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072b9a5-e0d2-4aa9-ad0e-cb469acc745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "#index = pc.list_indexes().names()[0]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a3a46-415b-47b4-8843-5221edb4548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd52b1-edbb-4a7e-86e3-abda3f7d8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora que ya está el indice, se van a crear los vectores\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac44f83-b5e2-42f7-b83d-5340b0b19e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[random.random() for _ in range(3072)] for v in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9053d2-1cf4-4587-88ae-4a5b51e33a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list('abcde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc93b8-208f-4b27-9324-3215f7e7a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574d8b1-3d5e-4c94-a9ee-8ad607ce0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'langchain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820952dc-0ed7-45bf-a290-f3e5ed5bea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96bb59f-02fb-43a5-a226-96cf59e54210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda los vectores en el index langchain\n",
    "index.upsert(vectors=zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d150636-3356-4dca-ab7f-be6683665e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se actualiza el vector C\n",
    "index.upsert(vectors=[('c',[0.5] * 3072)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b0df3-ee41-4bc0-aabe-b40e00370071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperamos los vectores\n",
    "index.fetch(ids=['c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2563a-7960-4b4d-bea2-17676aa74433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar vectores b y c\n",
    "index.delete(ids=['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d95744-7638-4e9e-a420-12dd091a7c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc88a2b-5e35-4009-ae9e-ecb24d70692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace una busqueda\n",
    "query_vector = [random.random() for _ in range(3072)]\n",
    "query_vector\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75271db3-93dd-4b15-ab44-e674c9af65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar los vectores que estan mas cerca al vector anterior\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    # Si se pone include_values=True, la salida incluye los valores de los vectores\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f53e79-5c11-4d3c-a48d-7f3d8ce8f4cf",
   "metadata": {},
   "source": [
    "### Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade4a84-c8b8-4452-9415-e04d98942800",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index('langchain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059bc68-f966-4511-8d59-9aca01947269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a1a7d-73ea-49ce-a76d-e2eacfbe83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [[random.random() for _ in range(3072)] for v in range(5)]\n",
    "ids = list('abcde')\n",
    "index.upsert(vectors=zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b558f83-4d50-4063-8bbc-c303b015847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora creamos tres vectores\n",
    "vectors = [[random.random() for _ in range(3072)] for v in range(3)]\n",
    "ids = list('xyz')\n",
    "index.upsert(vectors=zip(ids, vectors),namespace='primer-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340bb7e-fb96-4bf4-ab58-a01456bb5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora creamos dos vectores\n",
    "vectors = [[random.random() for _ in range(3072)] for v in range(2)]\n",
    "ids = list('qp')\n",
    "index.upsert(vectors=zip(ids, vectors),namespace='segundo-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708920fe-7b11-4698-970d-c0cf8827cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6e336-94a0-4b24-af41-35ec4165913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupero los valores de un namespace\n",
    "index.fetch(ids=['x'],namespace='primer-namespace')\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1bbb8-37b9-4f42-b552-b7ea94ce8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedo borrar un vector, pero para que sea efectivo el borrado, se debe incluir el namespace\n",
    "index.delete(delete_all=True, namespace= 'primer-namespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19568f6-4eb2-4ada-9697-4d77cb57e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ec908-a5ae-422e-a67b-f93075f54ce4",
   "metadata": {},
   "source": [
    "## Uso de langchain y Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a52ad1-9ef5-4516-aa87-bfdacfc263cd",
   "metadata": {},
   "source": [
    "### Splitting y Embedding textos usando LangChain (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb50ca0-c0f5-4f19-8ef4-3f3fa7fa3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0797501-35ee-4edc-b086-6caf83a21b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('La-Republilca-Platon.txt', encoding='utf-8') as f:\n",
    "    hp7 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36578083-9d3d-4f67-b353-bca64ffd1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=60,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c757076-b15c-42ef-8ab9-90b4dd753def",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.create_documents([hp7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64429279-da51-471b-a1d5-1a9c17ecbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impime la salida\n",
    "chunks\n",
    "# Para no saturar la pantalla, imprimo algo pequeño.\n",
    "#print(\"Algo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d3ff2-c4d9-42fa-8034-2f73e766c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a14b26-b3de-494c-a6bf-3251829d5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver cuántos fragmentos se tiene, se imprime el tamaño de los chunk.\n",
    "print(f'Hay {len(chunks)} fragmentos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06d118-c3f4-4da9-9294-7a34481ca89d",
   "metadata": {},
   "source": [
    "## Crear Embedding\n",
    "#### Pasamos los fragmentos en embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45fb59-e9f3-42fe-804e-be81e7bfad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ca53c-ba48-4c62-8fb5-7388420ac458",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google.genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731065f-6186-4bfc-98c1-76807d98a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model='text-embedding-3-large', dimensions=3072)\n",
    "# vector = embeddings.embed_query(chunks[0].page_content)\n",
    "# vector\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "text = chunks[0].page_content\n",
    "embeddings = client.models.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    contents=text,\n",
    "    config=types.EmbedContentConfig(output_dimensionality=92),\n",
    ")\n",
    "print(result.embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0d47e-15e6-428e-862f-c85bfa70945f",
   "metadata": {},
   "source": [
    "### Insertamos este vectore en pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adebc53-5cbe-4bd2-84b5-3075c3a6a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38ef60-fbe5-4a19-94ac-544bb3ef1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pinecone.Pinecone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba880e5-7a6f-4f48-8b10-ec3e1165645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos todos los indices\n",
    "indexes = pc.list_indexes().names()\n",
    "for i in indexes:\n",
    "    print('Borrando los indices ...', end='')\n",
    "    pc.delete_index(i)\n",
    "    print('Listo..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24c19d-f2f4-49bb-add6-52945e3559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se va a crear un indice con el contenido del libro\n",
    "from pinecone import PodSpec\n",
    "index_name = 'la-republica-platon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef6970-5088-4a89-9bd3-6e95ae0b30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta rutina no funciona porque la licencia no permite la creacion de indices desde el API\n",
    "#if index_name not in pc.list_indexes().names():\n",
    "#    print(f'Creando el indice {index_name}')\n",
    "#    pc.create_index(\n",
    "#        name=index_name,\n",
    "#        dimension=3072,\n",
    "#        metric='cosine',\n",
    "#        spec=PodSpec(\n",
    "#            environment='gcp-starter'\n",
    "#        )\n",
    "#    )\n",
    "#    print('Indice Creado')\n",
    "#else:\n",
    "#    print(f'Indice {index_name} ya existe!')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3f3f0-6e8e-4300-81d7-a1f90b569a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de un indice\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "#pc = Pinecone(api_key=\"YOUR_API_KEY\")\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f'Creando el indice {index_name}')\n",
    "    pc.create_index(\n",
    "      name=index_name,\n",
    "      dimension=3072,\n",
    "      metric=\"cosine\",\n",
    "      spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "      )\n",
    "    )\n",
    "    print('Indice Creado')\n",
    "else:\n",
    "    print(f'Indice {index_name} ya existe!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424a6c2-6ad1-4942-b711-65a46f055b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed525c-5c45-4d08-a80d-838354a8b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.vectorstores import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore.from_documents(\n",
    "        chunks,\n",
    "        index_name=index_name,\n",
    "        embedding=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11892fc-feab-45db-bdbe-b932aef88cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052299c-c5df-4e1a-8d5d-36b438bccc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a353ba-85bb-4cab-8e9e-911a22ef96de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
